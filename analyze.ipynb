{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "dictionary = json.load(open(\"words_dictionary.json\", \"r\"))\n",
    "print(\"alpha\" in dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"The Black Tulip, by Alexandre Dumas\"\n",
    "file = \"the_black_tulip.txt\"\n",
    "\n",
    "end_pattern = r\"End of Project Gutenberg's The Black Tulip\"\n",
    "chapter_pattern = r\"^Chapter \\d+.\"\n",
    "\n",
    "book = {}\n",
    "\n",
    "# create book\n",
    "chapter = \"\"\n",
    "content = \"\"\n",
    "with open(os.path.join(folder, file), \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if re.search(chapter_pattern, line) is not None:\n",
    "            # end of chapter\n",
    "            if chapter != \"\":\n",
    "                # refine content\n",
    "                content = content.strip().lower()\n",
    "                book[chapter] = content\n",
    "            # start new chapter\n",
    "            chapter = line\n",
    "            content = \"\"\n",
    "        elif re.search(end_pattern, line) is not None:\n",
    "            # end of chapter\n",
    "            if chapter != \"\":\n",
    "                # refine content\n",
    "                content = content.strip().lower()\n",
    "                book[chapter] = content\n",
    "            # end of book\n",
    "            break\n",
    "        else:\n",
    "            # add new chapter content\n",
    "            content += f\" {line}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 299.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "',-.;\"():?!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_key = [\"'\"]\n",
    "special_key = []\n",
    "# analyze book\n",
    "for chapter, content in tqdm(book.items()):\n",
    "    words = content.split(\" \")\n",
    "    for word in words:\n",
    "        special_word = re.sub(r\"[\\w]\", \"\", word)\n",
    "        for special_char in special_word:\n",
    "            if special_char not in special_key and special_char not in ignore_key:\n",
    "                special_key.append(special_char)\n",
    "\"\".join(special_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 253.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# words book\n",
    "from turtle import towards\n",
    "\n",
    "\n",
    "special_pattern = r'[,-\\.;\"\\(\\):\\?!]'\n",
    "words_book = {}\n",
    "words_chapter = {}\n",
    "for chapter, content in tqdm(book.items()):\n",
    "    # refresh chapter\n",
    "    words_chapter = {}\n",
    "    # refine special character\n",
    "    refine_content = re.sub(special_pattern, \".\", content)\n",
    "    # refine space and dot\n",
    "    refine_content = re.sub(r\"\\s+\", \" \", refine_content)\n",
    "    refine_content = re.sub(r\"\\s?\\.\\s?\", \".\", refine_content)\n",
    "    refine_content = re.sub(r\"[\\.]+\", \".\", refine_content)\n",
    "    refine_content = refine_content.strip()\n",
    "    sentences = refine_content.split(\".\")\n",
    "    for sentence in sentences:\n",
    "        if sentence == \"\":\n",
    "            continue\n",
    "        words = sentence.split()\n",
    "        counter = 0\n",
    "        while counter < len(words):\n",
    "            if counter + 1 < len(words):\n",
    "                two_gram = \" \".join(words[counter:counter + 2])\n",
    "                if two_gram in dictionary:\n",
    "                    counter += 2\n",
    "                    if two_gram not in words_chapter:\n",
    "                        words_chapter[two_gram] = 0\n",
    "                    words_chapter[two_gram] += 1\n",
    "                    continue\n",
    "            one_gram = words[counter]\n",
    "            counter += 1\n",
    "            if one_gram not in words_chapter:\n",
    "                words_chapter[one_gram] = 0\n",
    "            words_chapter[one_gram] += 1\n",
    "    # sort words chapter\n",
    "    sorted_words_chapter = dict(sorted(words_chapter.items(), key=lambda item: item[1], reverse=True))\n",
    "    # add chapter to book\n",
    "    refine_chapter = chapter.strip().lower()\n",
    "    words_book[refine_chapter] = sorted_words_chapter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "word_folder = \"words\"\n",
    "if not os.path.exists(os.path.join(folder, word_folder)):\n",
    "    os.mkdir(os.path.join(folder, word_folder))\n",
    "for chapter_name, words_chapter in words_book.items():\n",
    "    with open(os.path.join(folder, word_folder, chapter_name), \"w\") as file:\n",
    "        for word, word_count in words_chapter.items():\n",
    "            line = f\"{word_count}\\t-\\t{word}: \\n\"\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
